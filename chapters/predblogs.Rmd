# Blog: Prediction Challenges {#predblogs}

<script src="files/js/dcl.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

```{r ,include=FALSE}
tutorial::go_interactive(greedy=TRUE)
knitr::opts_chunk$set(echo = TRUE,error=TRUE)
```


Until we have studied multiple methods of data analysis in sections \@ref(freestyle),\@ref(datatransformation), statistical testing in sections \@ref(stateval), &   building prediction models for both classification \@ref(classification) and regression \@ref(regression) along with advanced ML models \@ref(models).

Now its time to utilize them in various ways for  analysis and prediction of data.

To do this, in this course, we have designed few prediction challenges, which test your ability to implement skills learnt in the course until now. 

First challenge is a basic prediction challenge using only data analysis using the freestyle techniques from section \@ref(freestyle). 

Then onwards, prediction challenges used multitude of modeling techniques which were studied in \@ref(classification) and \@ref(regression).

---

## General Structure of the Prediction Challenges.

Usually there is a task to be performed in each prediction challenge. 

Either predicting a numerical of categorical values is the task of each challenge.

The way to perform those task are constrained differently for different prediction challenges based on levels of difficulty and ML models to be used.

The submission will take place on **Kaggle** which is used for organizing these prediction challenges online, helping in validating submissions, placing deadlines for submission and also calculating the prediction scores along with ranking all the submission.

The datasets provided for each prediction challenge is as follows:

1. Training Dataset.
    - It is used for training and cross-validation purpose in the prediction challenge. 
    - This data has all the training attributes along and the ideal values of the prediction attribute.
    - Models for prediction are to be trained using this dataset only.
2. Testing Dataset.
    - It is used for prediction only.
    - It consists of all the attributes that were used for training, but it does not contain any values of the actual prediction attributes, which is actually the attribute that the prediction challenge predicts.
    - Since its only used for prediction purpose and is not involved in training of the models, it is thus not involved in the cross-validation phase too.
3. Submission Dataset.
    - After prediction using the "testing" dataset, for submitting on Kaggle, we must copy the predicted attribute column to this Submission Dataset which only has 2 columns, first an index column(e.g. ID or name,etc) and second the predicted attribute column.
    - Remember after copying the predicted attribute column to this dataset, one should also save this dataset into the same submission dataset file, which then can be used to upload on Kaggle.

- To read the datasets use the *read.csv()* function and for writing the dataset to the file, use the *write.csv()* function.
  - Offen times while writing the dataframe from R to a csv file, people make mistake of writing even the row names, which results in error upon submission of this file to Kaggle.
  - To avoid this, you can add the parameter, `row.names = F` in the `write.csv()` function. e.g. `write.csv(*dataframe*,*fileaddress*,row.names = F)`.

Now lets look at the prediction challenges that took place in this course along with the top submissions by students.

---


## Prediction Challange 1.

In Prediction challange 1, the task was to predict a categorical value using *only free-style* prediction. 

For this prediction challenge we used our favorite dataset, the Moody dataset, and predicted the Grade category of all students. The Grade category had only 2 factors: *Pass* OR *Fail*.

Let look at a snippet of the moody dataset used for training in this challenge.

```{r,echo=FALSE}
realestate<-read.csv("https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/dataset/M2021train.csv") #web load
temp<-knitr::kable(
  head(realestate, 10), caption = 'Snippet of Moody Dataset(TRAINING) for Prediction Challenge 1',
  booktabs = TRUE
)
library(kableExtra)
kableExtra::scroll_box(temp,width = "100%")

```

We can see that there are multiple attributes like *Score, Attendence, Major, etc.* that can be used as predictors, and then there is *Grade* attribute with ideal values for each record of student which will be used while training and then will be predicted on the testing dataset.

Lets look at the snippet of the moody dataset for testing.

```{r,echo=FALSE}
realestate<-read.csv("https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/dataset/M2021test-students.csv") #web load
temp<-knitr::kable(
  head(realestate, 10), caption = 'Snippet of Moody Dataset(TESTING) for Prediction Challenge 1',
  booktabs = TRUE
)
library(kableExtra)
kableExtra::scroll_box(temp,width = "100%")
```

We can see that the *Grade* attribute is not present in this dataset, since it is the attribute that will be predicted using our analysis of the training dataset.

Also, lets look at the submission file for prediction challenge 1.

```{r,echo=FALSE}
realestate<-read.csv("https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/dataset/M2021test-submission-file.csv") #web load
temp<-knitr::kable(
  head(realestate, 10), caption = 'Snippet of Submission file for Prediction Challenge 1',
  booktabs = TRUE
)
library(kableExtra)
kableExtra::scroll_box(temp,width = "100%")
```

We can see there are only 2 columns *Studentid* and *Grade*. *Studentid* column's entries corresponds/are similar to the *Studentid* column of the testing data. Thus we need to just fill the *Grade* column with appropriate grade predicted by our analysis, corresponding to the same *Studentid* values in both test and submission data.

Now that we have seen the data, feel free to go to the Kaggle site of this prediction challenge and take the challenge yourself. The link for challenge: [Prediction Challenge 1](https://www.kaggle.com/t/8099c3c8bd5940928d102a6ddda0ee3d){target="_blank"}

---

### Top Submissions for Challenge 1.

1. *Jeremy Prasad*

  - Jeremy performed exceptionally well in this prediction challenge.
  - His approach was a iterative learning process, where at each step after performing analysis he tried to decrease the error more and more.
  - He started with a very basic model, of using just the score attribute with a hard threshold for pass or fail grade based on the score value. 
  - After this, to increase accuracy, he analysed the data more found which attributes effect the prediction of the data, and which are not really useful
  - After finding these highly effective attributes, he wrote concrete set of attributs that can be used to assign the grade. Most of them were dependent on 2-3 attributes like Major-Senioriy-Score, Major-Score, or Major-Questions-Score,etc. 
  - This gave him a much better accuracy value for prediction. 


<button class="btn btn-primary" data-toggle="collapse" data-target="#Spectra" align="center">Jeremy's PPT</button>
<div id="Spectra" class="collapse">    
<object data="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/pred/jeremypred1.pdf" width="100%" height="500px"></object>
</div>


2. *Rohit  Manjunath*

  - Rohit performed well in this prediction challenge, and has a different approach than that of Jeremy's.
  - In Rohit's approach, instead of finding the minimum global threshold of pass or fail based on score, he found the threshold for the maximum score, above which every student passed the class.
  - He then analysed the data based on the Majors first and then found interval threshold for each Majors scores.
  - For some Majors, to increase accuracy, he further explored other attributes in detail to find which effects the final grade.
  - Rohit obtained accuracy of almost 85%.
  
<button class="btn btn-primary" data-toggle="collapse" data-target="#Spectra2" align="center">Rohit's PPT</button>
<div id="Spectra2" class="collapse">    
<object data="https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/pred/rohitpred1.pdf" width="100%" height="500px"></object>
</div>

---

## Predition Challenge 2 *

