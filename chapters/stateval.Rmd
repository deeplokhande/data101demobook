# Simple Statistical Evaluation {#stateval}

<script src="files/js/dcl.js"></script>
```{r ,include=FALSE}
tutorial::go_interactive(greedy=TRUE)
knitr::opts_chunk$set(echo = TRUE,error=TRUE)
```

The biggest enemy of your findings is randomness. In order to convince your audience that you have found something you need to address the question “how do you know your result is simply sheer luck, it is random?”

This is where you need statistical tests for use in hypothesis testing. 


#### *Some Basics First:

- _Mean_
\begin{equation}
\bar{X}=\frac{\sum{X}}{N}
\ \text{where, X is set of numbers and 
N is size of set.}
\end{equation}

- _Standard Deviation_

\begin{equation}

\sigma = \sqrt{\frac{\sum{(X - \mu)^2}}{N}}\\
\text{where, X is set of numbers, $\mu$ is average of set of numbers, }\\ \text{ N is size of the set, $\sigma$ is standard deviation}


\end{equation}


## Z-test {#ztest} 

A z-test is any statistical test used in hypothesis testing with an underlying normal distribution.

In other words, when the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution, z-test can be used.

Outcome of the z-test is the z-score which is a numerical measure to test the mean of a distribution.
z-score is measured in terms of standard deviation from mean.

### Steps for hypothesis testing using Z-test.

Running a Z-test requires 5 steps:

1. State the null hypothesis and the alternate hypothesis
    - Select a null hypothesis and an alternate hypothesis which will be tested using the z-test.
2. Choose an Alpha $\alpha$ level.
    - Usually this is selected to be small, such that the area under the normal distribution curve is accumulated most in the range between the alpha level.
    - Thus mostly in statistical testing, $\alpha = 0.05$ is selected.
3. Calculate the z-test statistic.
    - The z-test statistic is calculated using the z-score formula.
      \begin{equation} z = \frac{x-\mu}{\sigma}\text{ where, $z$ = z-score, $x$ = raw score, $\mu$ = mean and $\sigma$ = standard deviation } \end{equation}
4. Calculate the p-value using the z-score
    - Once we have the z-score we want to calculate the p-value from it.
    - To do this, there are 2 ways,
      - First use the z-table available online at [z-table.com](http://www.z-table.com/)
      - Second, use the pnorm() function in R to find the p-value.
5. Compare the p-value with $\alpha$
    - After getting the p-value from step 4, compare it with the $\alpha$ level we selected in step 2.
    - This decides if we can reject the null hypothesis or not.
      - If the p-value obtained is lower than $\alpha$, then we can reject the null hypothesis.
      - If the p-value is more than $\alpha$, we fail to reject the null hypothesis due to lack of significant evidence.
      
      
Some important relation between one-sided and two sided test while using hypothesis testing is as follows:

- First, estimate the expected value $\mu$ of T(statistic) under the null hypothesis, and obtain an estimate $\sigma$ of the standard deviation of T.
- Second, determine the properties of T : one tailed or two tailed.
  - For Null hypothesis H0: $\mu \geq \mu_0$ vs alternative hypothesis H1: $\mu < \mu_0$ , it is upper/right-tailed (one tailed).
  - For Null hypothesis H0:$\mu \leq \mu_0$ vs alternative hypothesis H1: $\mu > \mu_0$ , it is lower/left-tailed (one tailed).
  - For Null hypothesis H0: $\mu = \mu_0$ vs alternative hypothesis H1: $\mu \neq \mu_0$ , it is two-tailed.
- Once you calculate the pnorm() in step 4, depending on the properties of two as described above, 
  - use `pnorm(-Z)` for right tailed tests,
  - use `pnorm(Z)` for left tailed tests, and 
  - use `2*pnorm(-Z)` for two tailed test. 
  - *Note*: (Here Z = z-score). Also the method mentioned above works similar to that studied in class/recitations, but is simple to understand, and does not require subtracting the pnorm() output from 1.

Now lets look at an example to use this z-test for hypothesis testing.

We will study the example to statistically find the relation between two tunnels, Holland and Lincoln namely, with respect to the traffic volume per minute in those tunnels.

Thus stating out Null Hypothsis and Alternate Hypothesis.

- Null Hypothesis H0: Traffic in Lincoln is same as Traffic in Holland tunnel.
- Alternate Hypothesis H1: Traffic in Lincoln is higher than traffic in Holland tunnel.

Once we have stated our hypothesis, lets see the z-test in practice.

```{r}
# Load Dataset
TRAFFIC<-read.csv('https://raw.githubusercontent.com/deeplokhande/data101demobook/main/files/dataset/TRAFFIC.csv')
summary(TRAFFIC) #gives us the data statistics

#data clean and subset
lincoln.data <- subset(TRAFFIC, TRAFFIC$TUNNEL == "Lincoln")
holland.data <- subset(TRAFFIC, TRAFFIC$TUNNEL == "Holland")

# traffic at lincoln
# This variable is a column of 1401 rows.
lincoln.traffic <- lincoln.data$VOLUME_PER_MINUTE

# traffic at holland
# This variable is a column of 1401 rows.
holland.traffic <- holland.data$VOLUME_PER_MINUTE

# standard deviation of two samples.
# The final value is the standard deviation, in Volume per minute.
sd.lincoln <- sd(lincoln.traffic)
sd.holland <- sd(holland.traffic)

# means of two samples
mean.lincoln <- mean(lincoln.traffic)
mean.holland <- mean(holland.traffic)

# length of lincoln and holland
len_lincoln <- length(lincoln.traffic)
len_holland <- length(holland.traffic)

# standard deviation of traffic
sd.lin.hol <- sqrt(sd.lincoln^2/len_lincoln + sd.holland^2/len_holland)

# z score
zeta <- (mean.lincoln - mean.holland)/sd.lin.hol
zeta

# get p
p = pnorm(-zeta)
p

# plot the zeta value on the normal distribution curve.
plot(x=seq(from = -25, to= 25, by=0.1),y=dnorm(seq(from = -25, to= 25,  by=0.1),mean=0),type='l',xlab = 'mean difference',  ylab='possibility')
abline(v=zeta, col='red')
```

We can see that form the P-Value obtained is near to 0, which is less than 0.05. 

Hence, we reject the NULL Hypothesis and conclude with high degree of certainty that traffic in Lincoln is higher than traffic Holland. 

```{r child="./chapters/permutationtest.Rmd"}

```

## *Multiple Hypothesis - Bonferroni Correction.
